{
  "hash": "8c157ff4c476bbe6e5075bb36a9a6a78",
  "result": {
    "markdown": "---\nformat:\n  html: {toc: true, toc-depth: 4, theme: spacelab}\nhighlight-style: solarized\ncode-block-background: true\nembed-resources: false\nexecute: {freeze: true}\n\n---\n\n<style>\ntable {\n  border-style: thin;\n}\nth, td {\n  padding: 6px;\n}\ntd {\n  text-align: left;\n}\nth {\n  text-align: center;\n  background-color: #ddd;\n}\ntr:nth-child(even) {\n  background-color: #f6f6f6;\n}\n</style><style>\n.printedClojure .sourceCode {\n  background-color: transparent;\n  border-style: none;\n}\n</style>\n<div class=\"originalCode\">\n```clojure\n(ns chapter-2-input-output.2-1-loading-data\n  {:nextjournal.clerk/visibility {:code :hide}\n   :nextjournal.clerk/toc true}\n  (:require [scicloj.kind-clerk.api :as kind-clerk]))\n```\n</div>\n\n\n```{css}\nbody {font-size: 10em;}\n```\n\n\n\n<div class=\"originalCode\">\n```clojure\n(kind-clerk/setup!)\n```\n</div>\n\n\n\n<div class=\"printedClojure\">\n```clojure\n:ok\n\n```\n</div>\n\n;; This is a work in progress of the code examples that will make up chapter 2, section 1\n;; of the Clojure data cookbook\n;; # 2.1 How to get data into the notebook\n;; ## How to get data into the notebook\n;; ### Reading from a delimited text file\n;; Easiest with standard file formats, e.g. CSV.\n;; #### With Clojure's standard CSV library\n(require '[clojure.data.csv :as csv]\n'[clojure.java.io :as io])\n^{:nextjournal.clerk/viewer :table}\n(with-open [reader (io/reader \"data/co2_over_time.csv\")]\n(doall\n(csv/read-csv reader)))\n;; Returns: Lazy sequence of vectors of strings (one value per cell)\n;; TODO: Link to useful explainer on lazy seqs, explain why we include `doall` here\n;; #### With tablecloth\n;; For most work involving tabular/columnar data, you'll use tablecloth, Clojure's go-to data\n;; wrangling library. These all return a `tech.ml.dataset Dataset` object. The implementation\n;; details aren't important now, but `tech.ml.dataset` is the library that allows for efficient\n;; and fast operations on columnar datasets.\n;; TODO: Be consistent about you vs we -- pick on and stick with it\n(require '[tablecloth.api :as tc])\n(require '[nextjournal.clerk :as clerk])\n;; (clerk/add-viewers! [{:pred #(= tech.v3.dataset.impl.dataset.Dataset (type %))\n;;                       ;; :fetch-fn (fn [_ file] {:nextjournal/content-type \"image/png\"\n;;                       ;;                         :nextjournal/value (Files/readAllBytes (.toPath file))})\n;;                       :render-fn v/table}])\n(-> \"data/co2_over_time.csv\"\ntc/dataset)\n;; Note the built-in pretty printing.\n;; TODO: Write elsewhere about kindly and notebooks, how they know how to render different things\n;; Easy things to tidy up at import time:\n;; ##### Transforming headers\n;; We'll require Clojure's standard string library for this example. The transformation function is\n;; arbitrary though, accepting a single header value and returning a single, transformed value.\n(require '[clojure.string :as str])\n(defn- lower-case-keyword [val]\n(-> val\n(str/replace #\"\\s+\" \"-\")\nstr/lower-case\nkeyword))\n(-> \"data/co2_over_time.csv\"\n(tc/dataset {:key-fn lower-case-keyword}))\n;; ##### Specifying separators\n;; Tablecloth is pretty smart about standard formats, e.g. CSV above and TSV:\n(-> \"data/co2_over_time.tsv\"\ntc/dataset)\n;; But it can also accept an arbitrary separator if for some reason you have some data that uses\n;; a non-standard file format (have a look at `data/co2_over_time.txt`). Note the separator has to\n;; be a single character.\n(-> \"data/co2_over_time.txt\"\n(tc/dataset {:separator \"/\"}))\n;; ##### Specify file encoding\n;; TODO: does this really matter? test out different file encodings..\n;; ##### Normalize values into consistent formats and types\n;; Tablecloth makes it easy to apply arbitrary transformations to all values in a given column\n;; We can inspect the column metadata with tablecloth:\n(def dataset\n(tc/dataset \"data/co2_over_time.csv\"))\n(-> dataset\n(tc/info :columns))\n;; Certain types are built-in (it knows what to do to convert them, e.g. numbers:)\n;; TODO: Explain why numbers get rounded? Probably not here.. in addendum about numbers in Clojure\n(-> dataset\n(tc/convert-types \"CO2\" :double)\n(tc/info :columns))\n;; The full list of magic symbols representing types tablecloth supports comes from the underlying\n;; `tech.ml.dataset` library:\n(require '[tech.v3.datatype.casting :as casting])\n@casting/valid-datatype-set\n;; More details on [supported types here](https://github.com/techascent/tech.ml.dataset/blob/master/topics/supported-datatypes.md).\n;; TODO: Explain when to use :double vs :type/numerical? Whatâ€™s the difference?\n;; You can also process multiple columns at once, either by specifying a map of columns to data types:\n(-> dataset\n(tc/convert-types {\"CO2\" :double\n\"adjusted CO2\" :double})\n(tc/info :columns))\n;; Or by changing all columns of a certain type to another:\n(-> dataset\n(tc/convert-types :type/numerical :double)\n(tc/info :columns))\n;; The supported column types are:\n;; :type/numerical - any numerical type\n;; :type/float - floating point number (:float32 and :float64)\n;; :type/integer - any integer\n;; :type/datetime - any datetime type\n;; Also the magical `:!type` qualifier exists, which will select the complement set -- all columns that\n;; are _not_ the specified type\n;; For others you need to provide a casting function yourself, e.g. adding the UTC start of day,\n;; accounting for local daylight savings\n(defn to-start-of-day-UTC [local-date]\n(-> local-date\n.atStartOfDay\n(java.time.ZonedDateTime/ofLocal (java.time.ZoneId/systemDefault)\n(java.time.ZoneOffset/UTC))))\n(-> dataset\n(tc/convert-types \"Date\" [[:timezone-date to-start-of-day-UTC]])\n(tc/info :columns))\n;; For full details on all the possible options for type conversion of columns see the\n;; [tablecloth API docs](https://scicloj.github.io/tablecloth/index.html#Type_conversion)\n;; ### Reading from a URL\n;; CSV:\n(-> \"https://vega.github.io/vega-lite/data/co2-concentration.csv\"\ntc/dataset)\n;; JSON: works as long as the data is an array of maps\n(-> \"https://vega.github.io/vega-lite/data/cars.json\"\ntc/dataset)\n;; Tablecloth can handle a string that points to any file that contains either raw or gzipped csv/tsv,\n;; json, xls(x), on the local file system or a URL.\n;; ### Reading an excel file\n;; Tablecloth supports reading xls and xlsx files iff the underlying Java library for working with\n;; excel is included:\n(require '[tech.v3.libs.poi])\n;; This is not included in the library by default because `poi` has a hard dependency on log4j2, along\n;; with many other dependencies that the core team at `tech.ml.dataset` (upon which tablecloth is built)\n;; did not want to impose on all users by default (https://clojurians.zulipchat.com/#narrow/stream/236259-tech.2Eml.2Edataset.2Edev/topic/working.20with.20excel.20files/near/314711378).\n;; You can still require it here, you'll most likely just see an error that says something like\n;; \"Log4j2 could not find a logging implementation. Please add log4j-core to the classpath.\", unless\n;; you already have a valid log4j config on your class path.\n;; This should work according to maintainers, does not atm\n(tc/dataset \"data/example_XLS.xls\" {:filetype \"xls\"})\n(tc/dataset \"data/example_XLSX.xlsx\" {:filetype \"xlsx\"})\n(require '[dk.ative.docjure.spreadsheet :as xl])\n(def xl-workbook\n(xl/load-workbook \"data/example_XLS.xls\"))\n;; To discover sheet names:\n(->> xl-workbook xl/sheet-seq (map xl/sheet-name))\n;; This will show us there is only one sheet in this workbook, named \"Sheet1\". You can get the data\n;; out of it like this:\n;; To discover header names:\n(def headers\n(->> xl-workbook\n(xl/select-sheet \"Sheet1\")\nxl/row-seq\nfirst\nxl/cell-seq\n(map xl/read-cell)))\n;; To get the data out of the columns:\n(def column-index->header\n(zipmap [:A :B :C :D :E :F :G :H :I] headers))\n(->> xl-workbook\n(xl/select-sheet \"Sheet1\")\n(xl/select-columns column-index->header))\n;; and into a tablecloth dataset like this:\n(->> xl-workbook\n(xl/select-sheet \"Sheet1\")\n(xl/select-columns column-index->header)\n(drop 1) ;; don't count the header row as a row\ntc/dataset)\n;; You might be tempted to just iterate over each row and read each cell, but it's more\n;; convenient to think of the data as column-based rather than row-based for tablecloth's purposes.\n;; Setting the dataset headers is more verbose when we're starting from a seq of seqs, since\n;; the `header-row?` option does not work for a seq of seqs (this option is implemented in the\n;; low-level parsing code for each supported input type and is not currently implemented for\n;; a seq of seqs).\n(def iterated-xl-data\n(->> xl-workbook\n(xl/select-sheet \"Sheet1\")\nxl/row-seq\n(map #(->> % xl/cell-seq (map xl/read-cell)))))\n;; Note the `header-row?` option is not supported:\n(tc/dataset iterated-xl-data  {:header-row? true})\n;; Can do it manually, but just working with columns from the start is more idiomatic:\n(let [headers (first iterated-xl-data)\nrows (rest iterated-xl-data)]\n(map #(zipmap headers %) rows))\n;; ### Reading from a database\n;; #### SQL database\n;; (tc/dataset (,,, results from some SQL query))\n;; requires `com.github.seancorfield/next.jdbc {:mvn/version \"1.3.847\"}` in `deps.edn`\n;; Note you will also require the relevant driver for the type of db you are trying\n;; to access. These are some available ones:\n(require '[next.jdbc :as jdbc])\n;; Connect to the db:\n(def db {:dbname \"data/Chinook_Sqlite.sqlite\"\n:dbtype \"sqlite\"})\n(def ds (jdbc/get-datasource db))\nds\n;; Pass the results of a sql query to tablecloth to make a\n(-> ds\n(jdbc/execute! [\"SELECT * FROM artist\"])\n(tc/dataset))\n;; Passing a parameter to a query\n(-> ds\n(jdbc/execute! [\"SELECT * FROM artist WHERE Name = ?\" \"Aerosmith\"])\n(tc/dataset))\n;; note for SQLite specifically the concat operator is `||` not `+`\n(-> ds\n(jdbc/execute! [\"SELECT * FROM artist WHERE Name like '%' || ? || '%'\" \"man\"])\n(tc/dataset))\n;; #### SPARQL database\n(require '[grafter-2.rdf4j.repository :as repo])\n(require '[grafter-2.rdf.protocols :as pr])\n(def sparql (repo/sparql-repo \"https://query.wikidata.org/sparql\"))\n;; taken from: https://query.wikidata.org/#%23Public%20sculptures%20in%20Paris%0ASELECT%20DISTINCT%20%3Fitem%20%20%3FTitre%20%3Fcreateur%20%28year%28%3Fdate%29%20as%20%3FAnneeCreation%29%20%3Fimage%20%3Fcoord%0AWHERE%0A%7B%0A%20%20%20%3Fitem%20wdt%3AP31%2Fwdt%3AP279%2a%20wd%3AQ860861.%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20sculpture%0A%20%20%20%3Fitem%20wdt%3AP136%20wd%3AQ557141%20.%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20genre%C2%A0%3A%20art%20public%0A%20%20%20%7B%3Fitem%20wdt%3AP131%20wd%3AQ90.%7D%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20...%20situ%C3%A9e%20dans%20Paris%0A%20%20%20UNION%0A%20%20%20%7B%3Fitem%20wdt%3AP131%20%3Farr.%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20...%20ou%20dans%20un%20arrondissement%20de%20Paris%20%0A%20%20%20%3Farr%20wdt%3AP131%20wd%3AQ90.%20%7D%0A%20%20%20%3Fitem%20rdfs%3Alabel%20%3FTitre%20FILTER%20%28lang%28%3FTitre%29%20%3D%20%22fr%22%29.%20%20%23%20Titre%0A%20%0A%20%20%20OPTIONAL%20%7B%3Fitem%20wdt%3AP170%20%3FQcreateur.%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20cr%C3%A9ateur%2Fcr%C3%A9atrice%20%28option%29%0A%20%20%20%3FQcreateur%20rdfs%3Alabel%20%3Fcreateur%20FILTER%20%28lang%28%3Fcreateur%29%20%3D%20%22fr%22%29%20.%7D%0A%20%20%20OPTIONAL%20%7B%3Fitem%20wdt%3AP571%20%3Fdate.%7D%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20date%20de%20cr%C3%A9ation%20%28option%29%0A%20%20%20OPTIONAL%20%7B%3Fitem%20wdt%3AP18%20%20%3Fimage.%7D%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20image%20%28option%29%0A%20%20%20OPTIONAL%20%7B%3Fitem%20wdt%3AP625%20%3Fcoord.%7D%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20coordonn%C3%A9es%20g%C3%A9ographiques%20%28option%29%0A%7D\n(def sparql-results\n(let [conn (repo/->connection sparql)]\n(-> conn\n(repo/query\n\"# Public sculptures in Paris\nSELECT DISTINCT ?item  ?title ?creator (year(?date) as ?year) ?coord\nWHERE\n{\n?item wdt:P31/wdt:P279* wd:Q860861.                    # sculpture\n?item wdt:P136 wd:Q557141 .                            # genreÂ : art public\n{?item wdt:P131 wd:Q90.}                               # ... situÃ©e dans Paris\nUNION\n{?item wdt:P131 ?arr.                                  # ... ou dans un arrondissement de Paris\n?arr wdt:P131 wd:Q90. }\n?item rdfs:label ?title FILTER (lang(?title) = \\\"fr\\\").  # title\nOPTIONAL {?item wdt:P170 ?Qcreateur.                   # crÃ©ateur/crÃ©atrice (option)\n?Qcreateur rdfs:label ?creator FILTER (lang(?creator) = \\\"fr\\\") .}\nOPTIONAL {?item wdt:P571 ?date.}                       # date de crÃ©ation (option)\nOPTIONAL {?item wdt:P18  ?image.}                      # image (option)\nOPTIONAL {?item wdt:P625 ?coord.}                      # coordonnÃ©es gÃ©ographiques (option)\n}\"))))\n;; grafter db can help format RDF values\n(def sparql-ds\n(-> sparql-results\ntc/dataset\n(tc/update-columns [:coord :title :creator] (partial map pr/raw-value))))\n;; ### Generating sequences\n(defn seq-of-seqs [rows cols-per-row output-generator]\n(repeatedly rows (partial repeatedly cols-per-row output-generator)))\n;; Of random numbers:\n(defn random-number-between-0-1000 []\n(rand-int 1000))\n(seq-of-seqs 10 4 random-number-between-0-1000)\n(defn seq-of-maps [rows cols-per-row output-generator]\n(let [header-data (map #(str \"header-\" %) (range cols-per-row))\nrow-data (seq-of-seqs rows cols-per-row output-generator)]\n(map #(zipmap header-data %) row-data)))\n(seq-of-maps 10 4 random-number-between-0-1000)\n;; dtype next (library underneath tech.ml.dataset, which is underneath tablecloth) also\n;; has a built-in sequence generator:\n(require '[tech.v3.datatype :as dtype])\n(dtype/make-reader :string 4 (str \"cell-\" idx))\n(dtype/make-reader :int32 4 (rand-int 10))\n;; It is lazy, not cached, so be careful about using a computationally-heavy fn for generator\n;; ### Generating repeatable sequences of dummy data\n(def consistent-data\n(map-indexed (fn [index _coll] (str \"cell-\" index))\n(range 10)))\n(repeat (zipmap (range 10) consistent-data))\n:end\n<div style=\"background-color:grey;height:2px;width:100%;\"></div>\n<div><code><small><small>source: <a href=\"https://github.com/scicloj/kindly-noted/blob/main/book/chapter_2_input_output/2_1_loading_data.clj\">book/chapter_2_input_output/2_1_loading_data.clj</a></small></small></code></div>\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}